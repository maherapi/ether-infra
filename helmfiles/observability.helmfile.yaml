# Observability Stack Helmfile
# Deploys Prometheus, Grafana, Loki, Mimir for comprehensive monitoring and logging

environments:
  local:
    values:
      - ../environments/local.yaml
  staging:
    values:
      - ../environments/staging.yaml
  production:
    values:
      - ../environments/production.yaml

---
releases:
  # Prometheus Operator (includes Prometheus, Alertmanager, and CRDs)
  - name: kube-prometheus-stack
    condition: "{{ .Values.observability.prometheus.enabled }}"
    namespace: "{{ .Values.global.namespaces.observability }}"
    chart: "prometheus-community/kube-prometheus-stack"
    version: "55.5.0"
    values:
      # Prometheus Configuration
      - prometheus:
          prometheusSpec:
            replicas: "{{ .Values.observability.prometheus.replicas | default 1 }}"
            retention: "{{ .Values.observability.prometheus.retention }}"
            resources: "{{ .Values.observability.prometheus.resources }}"
            storageSpec:
              volumeClaimTemplate:
                spec:
                  storageClassName: "{{ .Values.global.storage.class }}"
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: "{{ .Values.observability.prometheus.storage.size }}"
            serviceMonitorSelectorNilUsesHelmValues: false
            ruleNamespaceSelector: {}
            ruleSelector: {}
            serviceMonitorNamespaceSelector: {}
            serviceMonitorSelector: {}
            podMonitorNamespaceSelector: {}
            podMonitorSelector: {}
            additionalScrapeConfigs:
              - job_name: 'ethereum-nodes'
                kubernetes_sd_configs:
                  - role: pod
                    namespaces:
                      names:
                        - "{{ .Values.global.namespaces.ethereum }}"
                relabel_configs:
                  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                    action: keep
                    regex: true
                  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                    action: replace
                    target_label: __metrics_path__
                    regex: (.+)
              - job_name: 'istio-mesh'
                kubernetes_sd_configs:
                  - role: endpoints
                    namespaces:
                      names:
                        - "{{ .Values.global.namespaces.istio }}"
                relabel_configs:
                  - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
                    action: keep
                    regex: istio-proxy;http-monitoring
              - job_name: 'registry'
                static_configs:
                  - targets: ['docker-registry.{{ .Values.global.namespaces.registry }}.svc.cluster.local:5000']

      # Grafana Configuration
      - grafana:
          enabled: "{{ .Values.observability.grafana.enabled }}"
          replicas: "{{ .Values.observability.grafana.replicas | default 1 }}"
          resources: "{{ .Values.observability.grafana.resources }}"
          persistence:
            enabled: "{{ .Values.observability.grafana.persistence.enabled | default false }}"
            size: "{{ .Values.observability.grafana.persistence.size | default \"5Gi\" }}"
            storageClassName: "{{ .Values.global.storage.class }}"
          adminPassword: "{{ .Values.observability.grafana.adminPassword }}"
          service:
            type: ClusterIP
            port: 80
          ingress:
            enabled: "{{ ne .Environment.Name \"local\" }}"
            hosts:
              - "grafana.{{ .Values.global.domain }}"
            tls:
              - secretName: grafana-tls
                hosts:
                  - "grafana.{{ .Values.global.domain }}"
          datasources:
            datasources.yaml:
              apiVersion: 1
              datasources:
                - name: Prometheus
                  type: prometheus
                  url: http://kube-prometheus-stack-prometheus:9090
                  access: proxy
                  isDefault: true
                - name: Loki
                  type: loki
                  url: http://loki:3100
                  access: proxy
                - name: Mimir
                  type: prometheus
                  url: http://mimir-nginx:80/prometheus
                  access: proxy
          dashboardProviders:
            dashboardproviders.yaml:
              apiVersion: 1
              providers:
                - name: 'ethereum'
                  orgId: 1
                  folder: 'Ethereum'
                  type: file
                  disableDeletion: false
                  editable: true
                  options:
                    path: /var/lib/grafana/dashboards/ethereum
                - name: 'infrastructure'
                  orgId: 1
                  folder: 'Infrastructure'
                  type: file
                  disableDeletion: false
                  editable: true
                  options:
                    path: /var/lib/grafana/dashboards/infrastructure
          dashboards:
            ethereum:
              ethereum-nodes:
                gnetId: 16074
                revision: 1
                datasource: Prometheus
              blockchain-metrics:
                file: dashboards/blockchain-metrics.json
            infrastructure:
              kubernetes-cluster:
                gnetId: 7249
                revision: 1
                datasource: Prometheus
              istio-mesh:
                gnetId: 7639
                revision: 173
                datasource: Prometheus

      # Alertmanager Configuration
      - alertmanager:
          alertmanagerSpec:
            replicas: "{{ .Values.observability.alertmanager.replicas | default 1 }}"
            retention: "{{ eq .Environment.Name \"production\" | ternary \"720h\" \"120h\" }}"
            resources:
              limits:
                cpu: 100m
                memory: 256Mi
              requests:
                cpu: 50m
                memory: 128Mi
            storage:
              volumeClaimTemplate:
                spec:
                  storageClassName: "{{ .Values.global.storage.class }}"
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 5Gi
            config:
              global:
                smtp_smarthost: 'localhost:587'
                smtp_from: 'alertmanager@{{ .Values.global.domain }}'
              route:
                group_by: ['alertname', 'severity']
                group_wait: 30s
                group_interval: 5m
                repeat_interval: 12h
                receiver: 'web.hook'
                routes:
                  - match:
                      severity: critical
                    receiver: 'critical-alerts'
                  - match:
                      alertname: EthereumNodeDown
                    receiver: 'ethereum-alerts'
              receivers:
                - name: 'web.hook'
                  webhook_configs:
                    - url: 'http://webhook-service/alerts'
                - name: 'critical-alerts'
                  webhook_configs:
                    - url: 'http://webhook-service/critical'
                {{- if and (eq .Environment.Name "production") .Values.observability.alertmanager.webhooks.slack }}
                  slack_configs:
                    - api_url: '{{ .Values.observability.alertmanager.slack.webhook_url }}'
                      channel: '#ethereum-alerts'
                      title: 'Critical Alert - {{ .Values.global.domain }}'
                {{- end }}
                - name: 'ethereum-alerts'
                  webhook_configs:
                    - url: 'http://webhook-service/ethereum'

  # Loki for Log Aggregation
  - name: loki
    condition: "{{ .Values.observability.loki.enabled }}"
    namespace: "{{ .Values.global.namespaces.observability }}"
    chart: "grafana/loki"
    version: "5.36.0"
    needs:
      - kube-prometheus-stack
    values:
      - deploymentMode: SingleBinary
      - loki:
          auth_enabled: false
          server:
            http_listen_port: 3100
            grpc_listen_port: 9095
          commonConfig:
            replication_factor: "{{ .Values.observability.loki.replicas | default 1 }}"
          storage:
            type: filesystem
          schema_config:
            configs:
              - from: 2020-10-24
                store: boltdb-shipper
                object_store: filesystem
                schema: v11
                index:
                  prefix: index_
                  period: 24h
          limits_config:
            retention_period: "{{ .Values.observability.loki.retention }}"
            ingestion_rate_mb: 16
            ingestion_burst_size_mb: 32
      - singleBinary:
          replicas: "{{ .Values.observability.loki.replicas | default 1 }}"
          resources: "{{ .Values.observability.loki.resources }}"
          persistence:
            enabled: true
            size: "{{ .Values.observability.loki.storage.size }}"
            storageClass: "{{ .Values.global.storage.class }}"
      - monitoring:
          selfMonitoring:
            enabled: true
            grafanaAgent:
              installOperator: false
          serviceMonitor:
            enabled: true
            labels:
              app: loki

  # Promtail for Log Collection
  - name: promtail
    condition: "{{ .Values.observability.loki.enabled }}"
    namespace: "{{ .Values.global.namespaces.observability }}"
    chart: "grafana/promtail"
    version: "6.14.1"
    needs:
      - loki
    values:
      - config:
          logLevel: info
          serverPort: 3101
          clients:
            - url: http://loki:3100/loki/api/v1/push
          positions:
            filename: /tmp/positions.yaml
          scrape_configs:
            - job_name: kubernetes-pods
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                  action: keep
                  regex: true
                - source_labels: [__meta_kubernetes_pod_container_name]
                  target_label: container
                - source_labels: [__meta_kubernetes_pod_name]
                  target_label: pod
                - source_labels: [__meta_kubernetes_namespace]
                  target_label: namespace
                - source_labels: [__meta_kubernetes_pod_label_app]
                  target_label: app
      - resources:
          limits:
            cpu: 200m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi

  # Mimir for Long-term Metrics Storage
  - name: mimir
    condition: "{{ .Values.observability.mimir.enabled }}"
    namespace: "{{ .Values.global.namespaces.observability }}"
    chart: "grafana/mimir-distributed"
    version: "5.1.3"
    needs:
      - kube-prometheus-stack
    values:
      - mimir:
          structuredConfig:
            multitenancy_enabled: false
            blocks_storage:
              backend: filesystem
              filesystem:
                dir: /data/tsdb
            compactor:
              data_dir: /data/compactor
              sharding_ring:
                kvstore:
                  store: memberlist
            distributor:
              ring:
                instance_addr: 127.0.0.1
                kvstore:
                  store: memberlist
            ingester:
              ring:
                instance_addr: 127.0.0.1
                kvstore:
                  store: memberlist
                replication_factor: 1
            ruler_storage:
              backend: filesystem
              filesystem:
                dir: /data/ruler
            server:
              http_listen_port: 8080
              grpc_listen_port: 9095
            store_gateway:
              sharding_ring:
                replication_factor: 1
      - ingester:
          replicas: "{{ .Values.observability.mimir.replicas | default 1 }}"
          resources: "{{ .Values.observability.mimir.resources }}"
          persistentVolume:
            enabled: true
            size: "{{ .Values.observability.mimir.storage.size }}"
            storageClass: "{{ .Values.global.storage.class }}"
      - store_gateway:
          replicas: 1
          resources:
            limits:
              cpu: 200m
              memory: 512Mi
          persistentVolume:
            enabled: true
            size: 10Gi
            storageClass: "{{ .Values.global.storage.class }}"
      - compactor:
          replicas: 1
          resources:
            limits:
              cpu: 200m
              memory: 512Mi
          persistentVolume:
            enabled: true
            size: 10Gi
            storageClass: "{{ .Values.global.storage.class }}"

repositories:
  - name: prometheus-community
    url: https://prometheus-community.github.io/helm-charts
  - name: grafana
    url: https://grafana.github.io/helm-charts

helmDefaults:
  createNamespace: true
  wait: true
  timeout: 600
  atomic: true
  cleanupOnFail: true
